{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Tell a story (period-separated sentences): Daniel picked up the apple there. Daniel went to the hallway. John moved to the office. Mary picked up the football there. Mary put down the football there. Mary picked up the football there. Daniel journeyed to the kitchen. Daniel travelled to the hallway. Daniel put down the apple. Mary moved to the kitchen.\n",
      "Ask a question: where is John?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/longw/.virtualenvs/mie1513-py3.5/lib/python3.5/re.py:203: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  office\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "import re\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "def tokenize(sent):\n",
    "    '''Return the tokens of a sentence including punctuation.\n",
    "    >>> tokenize('Bob dropped the apple. Where is the apple?')\n",
    "    ['Bob', 'dropped', 'the', 'apple', '.', 'Where', 'is', 'the', 'apple', '?']\n",
    "    '''\n",
    "    return [x.strip() for x in re.split('(\\W+)?', sent) if x.strip()]\n",
    "\n",
    "def embed_input(story, query, story_maxlen, query_maxlen):\n",
    "    story = [tokenize(sentence) for sentence in story]\n",
    "    query = tokenize(query)\n",
    "    \n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "    story = flatten(story)\n",
    "    \n",
    "    vocab = sorted(set(story + query))\n",
    "    #print(vocab)\n",
    "    \n",
    "    # Reserve 0 for masking via pad_sequences\n",
    "    vocab_size = len(vocab) + 1\n",
    "    \n",
    "    word_dict = dict((c, i + 1) for i, c in enumerate(vocab))\n",
    "    X = [word_dict[w] for w in story]\n",
    "    Xq = [word_dict[w] for w in query]\n",
    "    \n",
    "    X = pad_sequences([X], maxlen=story_maxlen)\n",
    "    Xq = pad_sequences([Xq], maxlen=query_maxlen)\n",
    "    \n",
    "    return X, Xq\n",
    "\n",
    "# load json and create model\n",
    "loaded_model_json = \"\"\n",
    "with open('model.json', 'r') as json_file:\n",
    "    loaded_model_json = json_file.read()\n",
    "\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into model\n",
    "loaded_model.load_weights(\"model_final.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "loaded_model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "with open(\"train_config\", \"r\") as f:\n",
    "    lines = f.read().splitlines()\n",
    "    story_maxlen = int(lines[0].split(\": \")[1])\n",
    "    query_maxlen = int(lines[1].split(\": \")[1])\n",
    "    word_idx = ast.literal_eval(lines[2])\n",
    "\n",
    "# use loaded model to respond to user input from command line\n",
    "user_story = input(\"Tell a story (period-separated sentences): \")\n",
    "user_story = user_story.strip().split(\". \")\n",
    "user_query = []\n",
    "while (user_query != 'q'):\n",
    "    #print(\"Ask a question:\")\n",
    "    user_query = input(\"Ask a question: \")\n",
    "    \n",
    "    story_test, query_test = embed_input(user_story, user_query, story_maxlen, query_maxlen)\n",
    "    #print('story_test:', story_test)\n",
    "    #print('query_test:', query_test)\n",
    "    \n",
    "    resp = loaded_model.predict([story_test, query_test])\n",
    "    resp = abs(np.ceil(resp-0.5))\n",
    "    i, decode_index = np.where(resp==1.)\n",
    "    #print(decode_index)\n",
    "    \n",
    "    for answer, encode in word_idx.items():\n",
    "        if encode == decode_index:\n",
    "            print(\"Answer: \", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daniel picked up the apple there. Daniel went to the hallway. John moved to the office. Mary picked up the football there. Mary put down the football there. Mary picked up the football there. Daniel journeyed to the kitchen. Daniel travelled to the hallway. Daniel put down the apple. Mary moved to the kitchen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
